"""
validate_obs.py - contains common code for when creating observational
data sets
"""
from __future__ import unicode_literals, division, absolute_import

import datetime
import json
import logging
import os

from netCDF4 import Dataset

import iris
import iris.exceptions

from django.utils import timezone

from pdata_app.models import ObservationDataset, ObservationFile
from pdata_app.utils.common import list_files, sha256
from vocabs.vocabs import CHECKSUM_TYPES

logger = logging.getLogger(__name__)


class ObsSet(object):
    """
    A class that represents an observational data set
    """
    # The attributes that are required in the class to fully describe an
    # observations set
    class_attributes = ['name', 'version', 'url', 'summary',
                        'date_downloaded', 'incoming_directory', 'doi',
                        'reference', 'license']
    django_attributes = ['name', 'version', 'url', 'summary',
                         'date_downloaded', 'doi', 'reference', 'license']

    def __init__(self, name=None, version=None, url=None, summary=None,
                 date_downloaded=None, incoming_directory=None, doi=None,
                 reference=None, license=None):
        """
        Create a new observation set.

        :param str name: The name of the set.
        :param str version: The set's version
        :param str url: The URL that the set can be downloaded from.
        :param str summary: A textual description of the set.
        :param datetime.datetime date_downloaded: When the set was
            downloaded.
        :param str incoming_directory: The local path that the set is
            stored at.
        """
        self.name = name
        self.version = version
        self.url = url
        self.summary = summary
        self.date_downloaded = date_downloaded
        self.doi = doi
        self.reference = reference
        self.license = license
        # The related observation files
        self.obs_files = []
        # This isn't needed for Django, but is convenient to hold in this class
        self.incoming_directory = incoming_directory

    @classmethod
    def from_dirname(cls, directory):
        """
        Create an observation set from a directory containing observations
        netCDF files.

        :param str directory:
        :return: An object containing metadata from the observation set and
            the observations files in the directory.
        :rtype: pdata_app.utils.validate_obs.ObsSet
        :raises ValueError: if the path specified is not a valid directory.
        """
        if not os.path.exists(directory):
            msg = 'Directory does not exist: {}'.format(directory)
            raise ValueError(msg)

        if not os.path.isdir(directory):
            msg = 'Path is not a directory: {}'.format(directory)
            raise ValueError(msg)

        return cls(incoming_directory=directory)

    @classmethod
    def from_json(cls, json_file):
        """
        Create an observation set from a JSON file, which was probably
        generated by this class but then manually edited by hand.

        :param str json_file: The path to the JSON file containing the
            metadata.
        :return: An object containing metadata from the observation set and
            the observations files in the directory.
        :rtype: pdata_app.utils.validate_obs.ObsSet
        """
        with open(json_file) as fh:
            metadata = json.load(fh, object_hook=_dict_to_object)

        obs_set = cls()

        for req_attr in cls.class_attributes:
            if req_attr not in metadata:
                msg = ('Attribute {} is missing from JSON file. Creating a '
                       'blank attribute: {}'.format(req_attr, json_file))
                logger.warning(msg)
                setattr(obs_set, req_attr, None)
            else:
                setattr(obs_set, req_attr, metadata[req_attr])

        # All times in the Django database are in UTC
        if isinstance(obs_set.date_downloaded, datetime.datetime):
            if obs_set.date_downloaded.tzinfo is None:
                obs_set.date_downloaded = timezone.make_aware(
                    obs_set.date_downloaded,
                    timezone.utc
                )

        if 'obs_files' not in metadata:
            msg = ('Attribute obs_files is missing from JSON file. Creating a '
                   'blank attribute: {}'.format(json_file))
            logger.warning(msg)
            setattr(obs_set, 'obs_files', [])
        else:
            obs_files = [ObsFile.from_dict(obs_file_dict)
                         for obs_file_dict in metadata['obs_files']]
            setattr(obs_set, 'obs_files', obs_files)

        return obs_set

    def to_json(self, json_filename):
        """
        Write all of the metadata from this object to the specified JSON file.
        A new JSON file is generated everytime; existing files will be
        overwritten.

        :param str json_filename: The path of the JSON file to save.
        """
        with open(json_filename, 'w') as fh:
            json.dump(self._to_dict(), fh, indent=4,
                      default=_object_to_default)

    def to_django_instance(self):
        """
        Convert this object into a Django pdata_app.models.ObservationDataset
        instance of the same observations set. Instances of each file in the
        set are also created.

        :returns: A Django instance of the same observations set saved in the
            current database.
        :rtype: pdata_app.models.ObservationDataset
        """
        django_set = ObservationDataset.objects.create(
            **{attr: getattr(self, attr) for attr in self.django_attributes}
        )
        for obs_file_obj in self.obs_files:
            ObservationFile.objects.create(
                obs_set=django_set,
                **{attr: getattr(obs_file_obj, attr)
                   for attr in obs_file_obj.class_attributes}
            )

    def add_files(self, only_netcdf=False):
        """
        Identify any files in the incoming directory and its subdirectories.
        Obtain all relevant metadata from each of the files found. There
        is also the option to ignore any files without a .nc suffix.

        :raises ValueError: if no files were found.
        """
        if only_netcdf:
            found_files = list_files(self.incoming_directory)
        else:
            found_files = list_files(self.incoming_directory, '')

        if not found_files:
            msg = ('No netCDF files found in directory or its subdirectories '
                   '{}'.format(self.incoming_directory))
            raise ValueError(msg)

        logger.debug('{} files identified'.format(len(found_files)))

        for found_file in found_files:
            obs_file = ObsFile(os.path.basename(found_file),
                               os.path.dirname(found_file))
            obs_file.add_metadata()
            self.obs_files.append(obs_file)

        logger.debug('{} files added'.format(len(self.obs_files)))

    def _to_dict(self):
        """
        Convert this observation set and its child observation files into
        a Python dictionary.

        :returns: The metadata from this observation set and its child
            observation files.
        :rtype: dict
        """
        obs_set_dict = {req_attr: getattr(self, req_attr)
                        for req_attr in self.class_attributes}
        obs_set_dict['obs_files'] = [obs_file.to_dict()
                                     for obs_file in self.obs_files]
        return obs_set_dict


class ObsFile(object):
    """
    A class that represents a single observations file
    """
    # The attributes that are used in the class to fully describe an
    # observations file
    class_attributes = ['name', 'incoming_directory', 'directory', 'tape_url',
                        'online', 'size', 'checksum_value', 'checksum_type',
                        'start_time', 'end_time', 'time_units', 'calendar',
                        'frequency', 'standard_name', 'long_name', 'var_name',
                        'units']

    def __init__(self, name, incoming_directory):
        """
        Create a blank observation file object.

        :param str name: The name of the file.
        :param str incoming_directory: The path to the directory containing
            the file.
        """
        self.name = name
        self.incoming_directory = incoming_directory
        self.directory = incoming_directory
        self.online = True

        self.tape_url = None
        self.size = None
        self.checksum_value = None
        self.checksum_type = None
        self.start_time = None
        self.end_time = None
        self.time_units = None
        self.calendar = None
        self.frequency = None
        self.standard_name = None
        self.long_name = None
        self.var_name = None
        self.units = None

    @classmethod
    def from_dict(cls, file_dict):
        """
        Create an object representing the metadata in an observations file
        from a dictionary of the metadata.

        :returns: an object describing the observations file.
        :rtype: pdata_app.utils.validate_obs.ObsFile
        """
        file_obj = cls(file_dict['name'], file_dict['incoming_directory'])

        for opt_attr in cls.class_attributes:
            if opt_attr in ['name', 'incoming_directory']:
                continue
            if opt_attr not in file_dict:
                msg = ('Attribute {} is not specified. Setting to None'.
                       format(opt_attr))
                logger.warning(msg)
                setattr(file_obj, opt_attr, None)
            else:
                setattr(file_obj, opt_attr, file_dict[opt_attr])

        return file_obj

    def add_metadata(self):
        """
        Load a file and gather as much metadata from it as possible.
        """
        logger.debug('Getting metadata for {}'.format(self.name))
        filepath = os.path.join(self.directory, self.name)
        self.size = os.path.getsize(filepath)
        self.checksum_value = sha256(filepath)
        self.checksum_type = CHECKSUM_TYPES['SHA256']
        if '_' in self.name:
            freq_string = self.name.split('_')[1]
            for freq in ['yr', 'mon', 'day', '6hr', '3hr', '1hr']:
                if freq in freq_string:
                    self.frequency = freq
                    break

        # If it's a netCDF file then we can get extra metadata
        if self.name.endswith('.nc'):
            logger.debug('Getting additional netCDF metadata for {}'.
                         format(self.name))
            try:
                cubes = iris.load(filepath)
            except TypeError as exc:
                logger.warning('Unable to load file using Iris {}: {}'.
                               format(self.name, exc.message))
                self._add_netcdf4_metadata()
            else:
                for cube in cubes:
                    # Take the time from the first cube that has a time
                    # Subsequent times will be ignored
                    if (not (self.time_units or self.calendar or
                             self.start_time or self.end_time)):
                        try:
                            time_coord = cube.coord('time')
                            self.time_units = str(time_coord.units)
                            self.calendar = time_coord.units.calendar
                            self.start_time = float(time_coord.points.min())
                            self.end_time = float(time_coord.points.max())
                            if self.time_units == 'unknown':
                                self.time_units = None
                        except iris.exceptions.CoordinateNotFoundError:
                            pass
                    for var_type in ['var_name', 'long_name', 'standard_name',
                                     'units']:
                        var_value = getattr(cube, var_type)
                        if var_value:
                            if var_type == 'units':
                                var_value = str(var_value)
                            if not getattr(self, var_type):
                                setattr(self, var_type, var_value)
                            else:
                                setattr(self, var_type,
                                        getattr(self, var_type) + ', ' +
                                        var_value)

    def to_dict(self):
        """
        Convert this observation file into a Python dictionary.

        :returns: The metadata from this observation file.
        :rtype: dict
        """
        return {req_attr: getattr(self, req_attr)
                for req_attr in self.class_attributes}

    def _add_netcdf4_metadata(self):
        """
        Get as much internal metadata as possible using the netCDF4 library.
        """
        logger.debug('Getting metadata using netCDF4 for {}'.format(self.name))
        filepath = os.path.join(self.directory, self.name)
        with Dataset(filepath) as rootgrp:
            if 'time' in rootgrp.dimensions:
                time_dim = rootgrp['time']
                self.time_units = time_dim.units
                self.calendar = time_dim.calendar
                self.start_time = float(time_dim[:].min())
                self.end_time = float(time_dim[:].max())

            for variable in rootgrp.variables:
                if variable not in rootgrp.dimensions:
                    for var_type in ['var_name', 'long_name', 'standard_name',
                                     'units']:
                        if var_type in rootgrp[variable].ncattrs():
                            var_value = rootgrp[variable].getncattr(var_type)
                            if var_type == 'units':
                                var_value = str(var_value)
                            if not getattr(self, var_type):
                                setattr(self, var_type, var_value)
                            else:
                                setattr(self, var_type,
                                        getattr(self, var_type) + ', ' +
                                        var_value)


def _object_to_default(obj):
    """
    Convert known objects to a form that can be serialized by JSON
    """
    if isinstance(obj, datetime.datetime):
        obj_dict = {'__class__': 'datetime',
                    '__module__': 'datetime'}
        datetime_attrs = ['year', 'month', 'day', 'hour', 'minute', 'second',
                          'microsecond']
        kwargs = {attr: int(getattr(obj, attr)) for attr in datetime_attrs}
        if obj.tzinfo:
            kwargs['tzinfo'] = obj.tzinfo
        obj_dict['__kwargs__'] = kwargs
        return obj_dict
    else:
        msg = 'Unknown type to save to JSON: {}'.format(obj.__class__.__name__)
        raise TypeError(msg)


def _dict_to_object(dict_):
    """
    Convert a dictionary loaded from a JSON file to an object
    """
    if '__class__' in dict_:
        module = __import__(dict_['__module__'], fromlist=[dict_['__class__']])
        klass = getattr(module, dict_['__class__'])
        # Check that this is a class that we're expecting
        if dict_['__class__'] in ['datetime']:
            inst = klass(**dict_['__kwargs__'])
        else:
            msg = ('Unknown type to load from JSON: {}'.
                   format(dict_['__class__']))
            raise TypeError(msg)
    else:
        inst = dict_
    return inst
